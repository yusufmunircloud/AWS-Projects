# Data Ingestion and Cataloging with AWS Glue
# Introduction
Welcome to this section on building a secure data lake with AWS Lake Formation. In this section, we'll focus on ingesting data into the raw landing zone and setting up a crawler using AWS Glue to create a data catalog. Our primary example will involve uploading a simple CSV file into the landing zone and then using Glue to catalog the data.

# Prerequisites
Ensure you have completed section 1, where we set up AWS Lake Formation, created buckets, databases, and linked them.

# Step 1: Uploading Data to Raw Landing Zone
1. Navigate to the S3 bucket named "Demo-Lake-Formation-Raw."

2. Inside the "input" folder, create a new folder named "customer."

3. Download the [customers.csv]() file and upload it into the "customer" folder.

# Step 2: Setting Up AWS Glue Crawler üõ†Ô∏è

1. Go to AWS Lake Formation and click on **"Crawlers"** in the left menu.
2. Click on **"Add Crawler"** and name it **"raw-customer-ingest."**
3. Select the source type as **"Data stores"** since we are not using an existing catalog table.
4. Choose **"S3"** as the data store, and navigate to the **"Demo-Lake-Formation-Raw/input/customer"** path.
5. Click on **"Next"** until you reach the **"Output"** section, where you can choose to add more data stores (skip for this tutorial).
6. Create a new IAM role named **"customer-ingest-role"** for the crawler.
7. Choose the frequency as **"Run on demand"** and click on **"Next."**
8. Select the raw database in AWS Lake Formation.
9. Optionally, prefix the table name, choose to create a single schema, and configure other options.
10. Set up handling schema changes and deleted objects according to your preferences.
11. Click on **"Next,"** review the settings, and click on **"Finish."**

# Step 3: Granting Permissions to IAM Role üîë

1. Go to AWS Lake Formation and click on **"Permissions"** in the left menu.
2. Grant the **"customer-ingest-role"** permission to the raw database with select, describe, insert, alter, delete, and drop privileges.
3. Ensure the role has permission to grant others.

# Step 4: Running the Glue Crawler üèÉ‚Äç‚ôÇÔ∏è

1. Go back to the AWS Glue console and click on **"Crawlers."**
2. Select the **"raw-customer-ingest"** crawler and click on **"Run Crawler."**
3. Wait for the crawler to complete (usually takes about one minute).

# Step 5: Querying the Data with Athena üìä

1. Open the Athena console.
2. Choose the **"Demo-Raw"** database.
3. You should see the **"sales_customer"** table under the **"Tables"** section.
4. Configure Athena settings to save query results to the **"Athena"** folder in the **"Demo-Lake-Formation-Raw"** bucket.
5. Run a simple query to preview the data.

# Conclusion üéâ

Congratulations! ü•≥ You have successfully ingested data into the raw landing zone, cataloged it using AWS Glue, and queried the data with Athena. In the next lesson, we'll explore more advanced data processing and transformation using AWS Glue Studio.
